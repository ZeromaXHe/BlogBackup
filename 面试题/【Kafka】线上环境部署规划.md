# 简答

**操作系统选型**：

Kafka 的生产环境集群首选 **Linux** 操作系统

原因：

- **I/O 模型的使用**。Kafka 新版本 clients 在设计底层网络库时采用了 Java 的 Selector 机制，而后者在 Linux 上的实现机制就是 epoll；但是在 Windows 平台上，Java NIO 的 Selector 底层是使用 select 模型而非 IOCP 实现的，只有 Java NIO2 才是使用 IOCP （属于异步 I/O）实现的。
- **数据网络传输效率**。在 Linux 平台上该方法底层会调用 sendfile 系统调用，即采用了 Linux 提供的零拷贝（Zero Copy）技术。对于 Windows 平台而言，虽然它也提供了 TransmitFile 函数来支持零拷贝技术，但是直到 Java 8u60 版本 Windows 平台才正式让 FileChannel 的 transferTo 方法调用该函数。
- 主流服务器通常在 Linux 上部署

**磁盘规划**：

- 追求性价比的公司可以考虑使用 **JBOD**。
- 使用**机械硬盘**完全可以满足 Kafka 集群的使用，**SSD** 更好。

**磁盘容量规划**：

磁盘容量的规划和以下多个因素有关：

- 新增消息数。
- 消息留存时间。
- 平均消息大小。
- 副本数。
- 是否启用压缩。

**内存规划**：

- 尽量分配更多的内存给操作系统的**页缓存**（page cache）。
- 不要为 broker 设置过大的**堆内存**，最好不超过 6GB。
- page cache 大小至少要大于一个**日志段**的大小。

**CPU 规划**：

- 使用**多核系统**，CPU 核数最好大于 8.
- 如果使用 Kafka 0.10.0.0 之前的版本或 clients 端与 broker 端消息版本不一致（若无显式配置，这种情况多半由 clients 和 broker 版本不一致造成），则考虑多配置一些资源以防止**消息解压缩操作**消耗过多 CPU。

**带宽规划**：

- 尽量使用**高速网络**。
- 根据自身网络条件和带宽来评估 Kafka 集群机器数量。
- 避免使用跨机房网络。

# 详解

典型的生产环境至少需要部署多个节点共同组成一个分布式集群整体为我们提供服务。

# 1 操作系统的选型

谈到操作系统，很多人可能会问：Kafka 不是 JVM 系的大数据框架吗？而 Java 又是跨平台的语言，那么使用什么操作系统有什么区别吗？当然有区别！

众所周知，Kafka 的服务器代码是由 Scala 语言编写的，而新版本客户端代码是由 Java 语言编写的。和 Java 一样，Scala 编译器会把源程序 .scala 文件编译成 .class 文件，因此 Scala 也是 JVM 系的语言。这样来看的话，貌似只要是支持 Java 程序部署的平台都应该能够部署 Kafka。但既然本章讨论的是生产环境的部署，那么我们就需要仔细地选型各种操作系统并梳理出它们对于 Kafka 的相适性。

目前部署 Kafka 最多的 3 类操作系统分别是 Linux、OS X 和 Windows，其中部署在 Linux 上的最多，而 Linux 也是推荐的操作系统。为什么呢？且不说当前的现状的确是 Linux 服务器数量最多，单论它与 Kafka 本身的相适性，Linux 也要比 Windows 等其他操作系统更加适合部署 Kafka。这里笔者罗列出自己能想到的两个主要原因：**I/O 模型的使用**和**数据网络传输效率**。

## 1.1 I/O 模型的使用

谈到 I/O 模型，就不能不说当前主流且耳熟能详的 5 种模型：阻塞 I/O、非阻塞 I/O、I/O 多路复用、信号驱动 I/O 和异步 I/O。每一种 I/O 模型都有典型的使用场景，比如 Socket 的阻塞模式和非阻塞模式就对应于前两种模型，而 Linux 中的 select 函数就属于 I/O 多路复用模型，至于第 5 种模型其实很少有 UNIX 和类 UNIX 系统支持，Windows 的 IOCP（I/O Completion Port，简称 IOCP）属于此模型。至于大名鼎鼎的 Linux epoll 模型，则可以看作兼具第 3 种和第 4 种模型的特性。

> 关于 select、epoll 具体介绍，可以参考[【Linux】IO 复用：select、poll、epoll 系统调用.md](./【Linux】IO 复用：select、poll、epoll 系统调用.md)

由于篇幅有限，我们不会针对每种 I/O 模型进行详细的展开，但通常情况下我们会认为 epoll 比 select 模型高级。毕竟 epoll 取消了轮询机制，取而代之的是回调机制（callback）。这样当底层连接 Socket 数较多时，可以避免很多无意义的 CPU 时间浪费。另外，Windows 的 IOCP 模型可以说是真正的异步 I/O 模型，但由于其母系统的局限性，IOCP 并没有广泛应用。

说了这么多，这些和 Kafka 又有什么关系呢？关键就在于 clients 底层网络库的设计。Kafka 新版本 clients 在设计底层网络库时采用了 Java 的 Selector 机制，而后者在 Linux 上的实现机制就是 epoll；但是在 Windows 平台上，Java NIO 的 Selector 底层是使用 select 模型而非 IOCP 实现的，只有 Java NIO2 才是使用 IOCP 实现的。因此在这一点上，在 Linux 上部署 Kafka 要比在 Windows 上部署能够得到更高效的 I/O 处理性能。

> **Java NIO**（New IO）是从 Java 1.4 版本开始引入的一个新的 IO API，可以替代标准的 Java IO API。NIO 与原来的 IO 有同样的作用和目的，但是使用的方式完全不同，NIO 支持面向缓冲区的、基于通道的 IO 操作。NIO 将以更加高效的方式进行文件的读写操作。
>
> 随着 JDK 7 的发布，Java 对 NIO 进行了极大的扩展，增强了对文件处理和文件系统特性的支持，以至于我们称他们为 **NIO 2**。因为 NIO 提供的一些功能，NIO 已经成为文件处理中越来越重要的部分

## 1.2 数据网络传输效率

对于第二个方面，即数据网络传输效率而言，Linux 也更有优势。具体来说，Kafka 这种应用必然需要大量地通过网络与磁盘进行数据传输，而大部分这样的操作都是通过 Java 的 `FileChannel.transferTo` 方法实现的。在 Linux 平台上该方法底层会调用 sendfile 系统调用，即采用了 Linux 提供的零拷贝（Zero Copy）技术。

这种零拷贝技术可以有效地改善数据传输的性能。在内核驱动程序处理 I/O 数据的时候，它可以减少甚至完全规避不必要的 CPU 数据拷贝操作，避免数据在操作系统内核地址空间和用户应用程序地址空间的缓冲区间进行重复拷贝，因而可以获得很好的性能。Linux 提供的诸如 mmap、sendfile 以及 splice 等系统调用即实现了这样的技术。

然而对于 Windows 平台而言，虽然它也提供了 TransmitFile 函数来支持零拷贝技术，但是直到 Java 8u60 版本 Windows 平台才正式让 FileChannel 的 transferTo 方法调用该函数。

鉴于很多公司目前的生产环境中还没有正式上线 Java 8，因而在 Windows 平台上部署 Kafka 将很有可能无法享受到零拷贝技术带来的高效数据传输。

综合以上两点差异以及目前主流服务器通常在 Linux 上部署的事实，笔者强烈推荐 Kafka 的生产环境集群首选 Linux 操作系统。

# 2 磁盘规划

前面主要讨论了该如何选择合适的操作系统平台来安装部署 Kafka。从现在开始，我们将分别从磁盘、内存、带宽和 CPU 等几个方面探讨部署 Kafka 集群所必要的关键规划因素。首先从磁盘开始说起。

如果问哪个因素对 Kafka 性能最重要？磁盘无疑是排名靠前的答案。众所周知，Kafka 是大量使用磁盘的。Kafka 的每条消息都必须被持久化到底层的存储中，并且只有被规定数量的 broker 成功接收后才能通知 clients 消息发送成功，因此消息越是被更快地保存在磁盘上，处理 clients 请求的延时越低，表现出来的用户体验也就越好。

> **《Kafka 权威指南》的对此的描述**：（意思等同于上文）
>
> 生产者客户端的性能直接受到服务器端磁盘吞吐量的影响。生产者生成的消息必须被提交到服务器保存，大多数客户端在发送消息之后会一直等待，直到至少有一个服务器确认消息已经成功提交为止。也就是说，磁盘写入速度越快，生成的延迟就越低。

## 2.1 机械硬盘还是固态硬盘

在确定磁盘时，一个常见问题就是选择普通的**机械硬盘**（HDD）还是**固态硬盘**（SSD）。机械硬盘成本低且容量大，而 SSD 通常有着极低的**寻道时间**（seek time）和**存取时间**（access time），性能上的优势很大，但同时也有着非常高的成本。因此在规划 Kafka 线上环境时，读者就需要根据公司自身的实际条件进行有针对性的选型。

但以笔者使用 Kafka 的经验来看，Kafka 使用磁盘的方式在很大程度上抵消了 SSD 提供的那些突出优势。众所周知，SSD 强就强在它不是机械装置，而全部由电子芯片及电路板组成，因而可以极大地避免传统机械硬盘缓慢地磁头寻道时间。一般机械硬盘的寻道时间都是毫秒级的。若有大量的随机 I/O 的性能，即使机械硬盘也是不弱的——顺序 I/O 不需要频繁地移动磁头，因此节省了耗时的寻道时间。所以从磁盘的使用这个方面来看，笔者并不认为两者有着巨大的性能差异。因此对于预算有限且追求高性价比的公司而言，机械硬盘完全可以胜任 Kafka 存储的任务。

> 其他方面的因素，比如磁盘特定的技术（串行连接存储技术或 SATA），或者磁盘控制器的质量，都会影响吞吐量。

## 2.2 JBOD 和 RAID

关于磁盘的选择，另一个比较热门的争论就在于，**JBOD** 和**磁盘阵列**（下称 RAID）之争。这里的 JBOD 全称是 Just Bunch Of Disks，翻译过来就是一堆普通磁盘的意思。在部署线上 Kafka 环境时，应当如何抉择呢？是使用一堆普通商用磁盘进行安装还是搭建专属的 RAID 呢？答案依然是具体问题具体分析。

首先分析一下 RAID 与 Kafka 的相适性。常见的 RAID 是 RAID 10，也被称为 RAID 1+0，它结合了磁盘镜像和磁盘条带化两种技术共同保护数据，既实现了不错的性能也提供了很高的可靠性。RAID 10 集合了 RAID 0 和 RAID 1 的优点，但在空间上使用了磁盘镜像，因此整体的磁盘使用率只有 50%，换句话说就是将一半的磁盘容量都用作提供冗余。自 Kafka 0.8.x 版本开始，用户就可以使用 RAID 作为存储来为 Kafka 提供服务了。事实上，根据公开的资料，LinkedIn 公司的 Kafka 集群就是使用 RAID 10 作为底层存储的。除了默认提供的数据冗余之外，RAID 10 还可以将数据自动地负载分布到多个磁盘上。

由此可见，RAID 作为 Kafka 的底层存储其实主要的优势有两个。

- 提供冗余的数据存储空间。
- 天然提供负载均衡。

以上两个优势对于任何系统而言都是非常好的特性。不过对于 Kafka 而言，在框架层面其实已经提供了这两个特性：通过副本机制提供冗余和高可靠性，以及通过分散到各个节点的领导者选举机制来实现负载均衡，所以从这方面来看，RAID 的优势就显得不是那么明显了。当然笔者绝没有全盘否定 RAID 的意思，实际上，依然有很多公司和组织使用或者打算在 RAID 之上构建 Kafka 集群。不过既然是资源规划和硬件选型，我们不妨看下 LinkedIn 公司是怎么做的。

之前提到过，LinkedIn 公司目前的 Kafka 就搭建于 RAID 10 之上。他们在 Kafka 层面设定的副本数是 2，因此根据 RAID 10 的特性，这套集群实际上提供了 4 倍的数据冗余，且只能容忍一台 broker 宕机（因为副本数=2）。若 LinkedIn 公司把副本数提高到 3 ，那么就提供了 6 倍的数据冗余。这将是一笔很大的成本开销。

但是，如果我们假设 LinkedIn 公司使用的是 JBOD 方案。虽然目前 JBOD 有诸多限制，但其低廉的价格和超高的性价比的确是非常大的优势。另外通过一些简单的设置，JBOD 方案可以达到和 RAID 方案一样的数据冗余效果。比如说，如果使用 JBOD 并且设置副本数为 4，那么 Kafka 集群依然提供 4 倍的数据冗余，但是这个方案中整个集群可以容忍最多 3 台 broker 宕机而不丢失数据。对比之前的 RAID 方案，JBOD 方案没有牺牲任何高可靠性或是增加硬件成本，同时还提升了整个集群的高可用性。

事实上，LinkedIn 公司目前正在计划将整个 Kafka 集群从 RAID 10 迁移到 JBOD 上，只不过在整个过程中 JBOD 方案需要解决当前 Kafka 一些固有缺陷，比如：

- 任意磁盘损坏都会导致 broker 宕机——普通磁盘损坏的概率是很大的，因此这个缺陷从某种程度上来说是致命的。不过社区正在改进这个问题，未来版本中只要为 broker 配置的多块磁盘中还有状态良好的磁盘，broker 就不会挂掉。
- JBOD 的管理需要更加细粒度化——目前 Kafka 没有提供脚本或其他工具用于在不同磁盘间进行分区手动分配，但这是使用 JBOD 方案中必要的功能。
- JBOD 也应该提供类似于负载均衡的功能——目前只是简单地依赖轮询的方式为新副本数据选择磁盘，后续需要提供更加丰富的策略。

结合 JBOD 和 RAID 之间的优劣对比以及 LinkedIn 公司的实际案例，笔者认为：对于一般的公司或组织而言，选择 JBOD 方案的性价比更高。另外推荐用户为每个 broker 都配置多个日志路径，每个路径都独立挂载在不同的磁盘上，这使得多块物理磁盘磁头同时执行物理 I/O 写操作，可以极大地加速 Kafka 消息生产的速度。

最后关于磁盘的一个建议就是，尽量不要使用 **NAS**（Network Attached Storage）这样的网络存储设备。对比本地存储，人们总是认为 NAS 方案速度更快也更可靠，其实不然。NAS 一个很大的弊端在于，它们通常都运行在低端的硬件上，这就使得它们的性能很差，可能比一台笔记本电脑的硬盘强不了多少，表现为平均延时有很大的不稳定性，而几乎所有高端的 NAS 设备厂商都售卖专有的硬件设备，因此成本的开销也是一个需要考虑的因素。

综合以上所有的考量，笔者给硬盘规划的结论性总结如下：

- 追求性价比的公司可以考虑使用 JBOD。
- 使用机械硬盘完全可以满足 Kafka 集群的使用，SSD 更好。

# 3 磁盘容量规划

Kafka 集群到底需要多大的磁盘容量？这又是一个非常经典的规划问题。如前所述，Kafka 的每条消息都保存在实际的物理磁盘中，这些消息默认会被 broker 保存一段时间之后清除。这段时间是可以配置的，因此用户可以根据自身实际业务场景和存储需求来大致计算线上环境所需的磁盘容量。

让我们以一个实际的例子来看下应该如何思考这个问题。假设在你的业务场景中，clients 每天会产生 1 亿条消息，每条消息保存两份并保留一周的时间，平均一条消息的大小是 1KB，那么我们需要为 Kafka 规划多少磁盘空间呢？如果每天 1 亿条消息，那么每天产生的消息会占用 1 亿 * 2 * 1KB / 1000 / 1000 = 200GB 的磁盘空间。我们最好再额外预留 10% 的磁盘空间用于其他数据文件（比如索引文件等）的存储，因此在这种使用场景下每天新发送的消息将占用 210 GB 左右的磁盘空间。因为还要保存一周的数据，所以整体的磁盘容量规划是 210 * 7 ≈ 1.5 TB。当然，这是无压缩的情况。如果在 clients 启用了消息压缩，我们可以预估一个平均的压缩比（比如 0.5），那么整体的磁盘容量就是 0.75TB。

总之对于磁盘容量的规划和以下多个因素有关：

- 新增消息数。
- 消息留存时间。
- 平均消息大小。
- 副本数。
- 是否启用压缩。

# 4 内存规划

乍一看似乎关于内存规划的讨论没什么必要，毕竟用户能做的就只是分配一个合适大小的内存，其他也没有什么可以调整的地方了。其实不然！Kafka 对于内存的使用可称作其设计亮点之一。虽然在前面我们强调了 Kafka 大量依靠文件系统和磁盘来保存消息，但其实它还会对消息进行缓存，而这个消息缓存的地方就是内存，具体来说是操作系统的**页缓存**（page cache）。

Kafka 虽然会持久化每条消息，但其实这个工作都是底层的文件系统来完成的，Kafka 仅仅将消息写入了 page cache 而已，之后将消息“冲刷”到磁盘的任务完全交由操作系统来完成。另外 consumer 在读取消息时也会首先尝试从该区域中查找，如果直接命中则完全不用执行耗时的物理 I/O 操作，从而提升了 consumer 的整体性能。不论是缓冲已发送消息还是待读取消息，操作系统都要先开辟一块内存区域用于存放接收的 Kafka 消息，因此这块内存区域大小的设置对于 Kafka 的性能就显得尤为关键了。

有些令人惊讶的是，Kafka 对于 Java 堆内存的使用反而不是很多，因为 Kafka 中的消息通常都属于“朝生夕灭”的对象实例，可以很快地垃圾回收（GC）。一般情况下，broker 所需的堆内存都不会超过 6GB。所以对于一台 16GB 内存的机器而言，文件系统 page cache 的大小甚至可以达到 10 ~ 14GB！

除以上这些考量之外，用户还需要把 page cache 大小与实际线上环境中设置的日志段大小相比较。假设单个日志段文件大小设置为 10GB，那么你至少应该给予 page cache 10GB 以上的内存空间。这样，待消费的消息有很大概率会保存在页缓存中，故 consumer 能够直接命中页缓存而无须执行缓慢的磁盘 I/O 读操作。

总之对于内存规划的建议如下：

- 尽量分配更多的内存给操作系统的 page cache。
- 不要为 broker 设置过大的堆内存，最好不超过 6GB。
- page cache 大小至少要大于一个日志段的大小。

# 5 CPU 规划

比起磁盘和内存，CPU 于 Kafka 而言并没有那么重要——严格来说，Kafka 不属于**计算密集型**（CPU-bound）的系统，因此对于 CPU 需要记住一点就可以了：**追求多核而非高时钟频率**。

简单来说，Kafka 的机器有 16 个 CPU 核这件事情比该机器 CPU 时钟高达 4GHz 更加重要，因为 Kafka 可能无法充分利用这 4GHz 的频率，但几乎肯定会用满 16 个 CPU 核。Kafka broker 通常会创建几十个后台线程，再加上多个垃圾回收线程，多核系统显然是最佳的配置选择。

当然，凡事皆有例外。若 clients 端启用了消息压缩，那么除了要为 clients 机器分配足够的 CPU 资源外，broker 端也有可能需要大量的 CPU 资源——尽管 Kafka 0.10.0.0 改进了在 broker 端的消息处理，免除了解压缩消息的负担以节省磁盘占用和网络带宽，但并非所有情况下都可以避免这种解压缩（比如 clients 端和 broker 端配置的消息版本号不匹配）。若出现这种情况，用户就需要为 broker 端的机器也配置充裕的 CPU 资源。

基于以上的判断依据，我们对 CPU 资源规划的建议如下：

- 使用多核系统，CPU 核数最好大于 8.
- 如果使用 Kafka 0.10.0.0 之前的版本或 clients 端与 broker 端消息版本不一致（若无显式配置，这种情况多半由 clients 和 broker 版本不一致造成），则考虑多配置一些资源以防止消息解压缩操作消耗过多 CPU。

# 6 带宽规划

对于 Kafka 这种在网络间传输大量数据的分布式数据管道而言，带宽资源至关重要，并且特别容易成为系统的瓶颈，因此一个快速且稳定的网络是 Kafka 集群搭建的前提条件。低延时的网络以及高宽带有助于实现 Kafka 集群的高吞吐量以及用户请求处理低延时。

当前主流的网络环境皆是使用以太网，带宽主要也有两种：1Gb/s 和 10Gb/s，即平时所说的千兆位网络和万兆位网络。无论是哪种带宽，对于大多数的 Kafka 集群来说都足矣了。

前面的磁盘容量规划中给出了一种用于评估磁盘容量的方法。使用该方法我们可以估算出 Kafka 集群所需的磁盘空间。结合每台 broker 本身的磁盘容量，就可以计算出整个集群需要的机器数。除了磁盘的因素，我们还必须根据实际业务网络环境来考量带宽的影响。

举一个实际的例子来说明如何规划带宽资源。假设用户网络环境中带宽是 1Gb/s，用户的业务目标是每天用 1 小时处理 1TB 的业务消息，那么在这种情况下 Kafka 到底需要多少台机器呢？让我们来计算一下：

网络带宽是 1Gb/s，即每秒传输 1Gb 的数据，假设分配的机器为 Kafka 专属使用（通常不建议与其他应用或是框架部署在同一台机器上）且为 Kafka 分配 70% 的带宽资源——考虑到机器上还有其他的进程使用网络且网卡通常不能用满，超过一定阈值可能出现网络丢包的情况，因此 70% 的设定实际上是很合理的——那么 Kafka 单台就是 1Gb/s * 0.7 ≈ 710Mb/s。

但事实上这是 Kafka 所使用的最高带宽，用户不能奢望 Kafka 集群平时就一直使用如此多的带宽，毕竟万一碰到突发流量，会极容易把网卡“打满”，因此在 70% 的基础上，一般再截取 1/3，即 710Mb/s / 3 ≈ 240 Mb/s。这里的 1/3 是一个相对保守的数字，用户可以根据自身的业务特点酌情增加。

好了，根据现有的网络情况，我们明确了单台 broker 的带宽是 240Mb/s。如果要在 1 小时内处理 1TB 的业务消息，即每秒需要处理 292MB 左右的数据，也就是这个数字还需要再翻 1 倍，即 20 台 broker 机器。根据万兆位网卡来评估 broker 机器的方法是类似的。

关于带宽资源方面的规划，用户还需要注意的是尽量避免使用跨机房的网络环境，特别是那些跨城市甚至是跨大洲的网络。因为这些网络条件下请求的延时将会非常高，不管是 broker 端还是 clients 端都需要额外做特定的配置才能适应。

综合上述内容，我们对带宽资源规划的建议如下：

- 尽量使用高速网络。
- 根据自身网络条件和带宽来评估 Kafka 集群机器数量。
- 避免使用跨机房网络。

# 7 典型线上环境配置

下面给出一份典型的线上环境配置，用户可以参考这份配置以及结合自己的实际情况进行二次调整。

- CPU 24核
- 内存 32GB
- 磁盘 1TB 7200 转 SAS 盘两块
- 带宽 1Gb/s
- ulimit -n 1000000
- Socket Buffer 至少 64 KB——适用于跨机房网络传输

# 8 Kafka 集群

单个 Kafka 服务器足以满足本地开发或 POC（Proof of Concept，即概念验证)要求，不过集群也有它的强大之处。典型的生产环境至少需要部署多个节点共同组成一个分布式集群整体为我们提供服务。使用集群的最大的好处是可以跨服务器进行负载均衡，再则就是可以使用复制功能来避免因单点故障造成的数据丢失。在维护 Kafka 或底层系统时，使用集群可以确保为客户端提供高可用性。

## 8.1 需要多少个 broker

一个 Kafka 集群需要多少个 broker 取决于以下几个因素：

- 首先，需要多少磁盘空间来保留数据，以及单个 broker 有多少空间可用。如果整个集群需要保留 10TB 的数据，每个 broker 可以存储 2TB，那么至少需要 5 个 broker。如果启用了数据复制，那么至少还需要一倍的空间，不过这要取决于配置的复制系数是多少。也就是说，如果启用了数据复制，那么这个集群至少需要 10 个 broker。
- 第二个要考虑的因素是集群处理请求的能力。这通常与网络接口处理客户端流量的能力有关，特别是当有多个消费者存在或者在数据保留期间流量发生波动（比如高峰时段的流量爆发）时。如果单个 broker 的网络接口在高峰时段可以达到 80% 的使用量，并且有两个消费者，那么消费者就无法保持峰值，除非有两个 broker。如果集群启用了复制功能，则要把这个额外的消费者考虑在内。因磁盘吞吐量低和系统内存不足造成的性能问题，也可以通过扩展多个 broker 来解决。

## 8.2  broker 配置

要把一个 broker 加入到集群里，只需要修改两个配置参数。

首先，所有 broker 都必须配置相同的 `zookeeper.connect`，该参数指定了用于保存元数据的 Zookeeper 群组和路径。

其次，每个 broker 都必须为 `broker.id` 参数设置唯一的值。如果两个 broker 使用相同的 `broker.id`，那么第二个 broker 就无法启动。

在运行集群时，还可以配置其他一些参数，特别是那些用于控制数据复制的参数。

## 8.3 操作系统调优

大部分 Linux 发行版默认的内核调优参数配置已经能够满足大多数应用程序的运行需求，不过还是可以通过调整一些参数来进一步提升 Kafka 的性能。这些参数主要与虚拟内存、网络子系统和用来存储日志片段的磁盘挂载点有关。这些参数一般配置在 `/etc/sysctl.conf` 文件里，不过在对内核参数进行调整时，最好参考操作系统的文档。

### 8.3.1 虚拟内存

一般来说，Linux 的虚拟内存会根据系统的工作负荷进行自动调整。我们可以对交换分区的处理方式和内存脏页进行调整，从而让 Kafka 更好地处理工作负载。

对于大多数依赖吞吐量的应用程序来说，要尽量避免内存交换。内存页和磁盘之间的交换对 Kafka 各方面的性能都有重大影响。Kafka 大量地使用系统页面缓存，如果虚拟内存被交换到磁盘，说明已经没有多余内存可以分配给页面缓存了。

一种避免内存交换的方法是不设置任何交换分区。内存交换不是必需的，不过它确实能够在系统发生灾难性错误时提供一些帮助。进行内存交换可以防止操作系统由于内存不足而突然终止进程。基于上述原因，建议把 `vm.swappiness` 参数的值设置得小一点，比如 1。该参数指明了虚拟机的子系统将如何使用交换分区，而不是只把内存页从页面缓存里移除。要优先考虑减小页面缓存，而不是进行内存交换。

> **为什么不把 `vm.swappiness` 设为零**
>
> 先前，人们建议尽量把 `vm.swappiness` 设为 0，它意味着“除非发生内存溢出，否则不要进行内存交换”。直到 Linux 内核 3.5-rc1 版本发布，这个值的意义才发生了变化。这个变化被移植到其他的发行版上，包括 Red Hat 企业版内核 2.6.32-303。在发生变化之后，0 意味着“在任何情况下都不要发生交换”。所以现在建议把这个值设为 1。

脏页会被冲刷到磁盘上，调整内核对脏页的处理方式可以让我们从中获益。Kafka 依赖 I/O 性能为生产者提供快速的响应。这就是为什么日志片段一般要保存在快速磁盘上，不管是单个快速磁盘（如 SSD）还是具有 NVRAM 缓存的磁盘子系统（如 RAID）。这样一来，在后台刷新进程将脏页写入磁盘之前，可以减少脏页的数量，这个可以通过将 `vm.dirty_background_ratio` 设为小于 10 的值来实现。

该值指的是系统内存的百分比，大部分情况下设为 5 就可以了。它不应该被设为 0，因为那样会促使内核频繁地刷新页面，从而降低内核为底层设备的磁盘写入提供缓冲的能力。

通过设置 `vm.dirty_ratio` 参数可以增加被内核进程刷新到磁盘之前的脏页数量，可以将它设为大于 20 的值（这也是系统内存的百分比）。这个值可设置的范围很广，60 ~ 80 是个比较合理的区间。不过调整这个参数会带来一些风险，包括未刷新磁盘操作的数量和同步刷新引起的长时间 I/O 等待。如果该参数设置了较高的值，建议启动 Kafka 的复制功能，避免因系统崩溃造成数据丢失。

为了给这些参数设置合适的值，最好是在 Kafka 集群运行期间检查脏页的数量，不管是在生存环境还是模拟环境。可以在 `/proc/vmstat` 文件里查看当前脏页数量。

### 8.3.2 磁盘

除了选择合适的磁盘硬件设备和使用 RAID 外，文件系统是影响性能的另一个重要因素。有很多种文件系统可供选择，不过对于本地文件系统来说，EXT4（第四代可扩展文件系统）和 XFS 最为常见。

近来，XFS 成为很多 Linux 发行版默认的文件系统，因为它只需要做少量调优就可以承担大部分的工作负荷，比 EXT4 具有更好的表现。EXT4 也可以做得很好，但需要做更多的调优，存在较大的风险。其中就包括设置更长的提交间隔（默认是 5），以便降低刷新的频率。EXT4 还引入了块分配延迟，一旦系统崩溃，更容易造成数据丢失和文件系统毁坏。XFS 也使用了分配延迟算法，不过比 EXT4 的要更安全些。XFS 为 Kafka 提供了更好的性能，除了由文件系统提供的自动调优之外，无须额外的调优。批量磁盘写入具有更高的效率，可以提升整体的 I/O 吞吐量。

不管使用哪一种文件系统来存储日志片段，最好要对挂载点的 `noatime` 参数进行合理的设置。文件元数据包含 3 个时间戳：创建时间（ctime）、最后修改时间（mtime）以及最后访问时间（atime）。默认情况下，每次文件被读取后都会更新 atime，这会导致大量的磁盘写操作，而且 atime 属性的用处不大，除非某些应用程序想要知道某个文件在最近一次修改后有没有被访问过（这种情况可以使用 `realtime`）。Kafka 用不到该属性，所以完全可以把它禁用掉。为挂载点设置 `noatime` 参数可以防止更新 atime，但不会影响 ctime 和 mtime。

### 8.3.3 网络

默认情况下，系统内核没有针对快速的大流量网络传输进行优化，所以对于应用程序来说，一般需要对 Linux 系统的网络栈进行调优，以实现对大流量的支持。实际上，调整 Kafka 的网络配置与调整其他大部分 web 服务器和网络应用程序的网络配置是一样的。

首先可以对分配给 socket 读写缓冲区的内存大小作出调整，这样可以显著提升网络的传输性能。socket 读写缓冲区对应的参数分别是 `net.core.wmem_default` 和 `net.core.rmem_default`，合理的值是 131072（也就是 128KB）。读写缓冲区最大值对应的参数分别是 `net.core.wmem_max` 和 `net.core.rmem_max`，合理的值是 2097152（也就是 2MB）。要注意，最大值并不意味着每个 socket 一定要有这么大的缓冲空间，只是说在必要的情况下才会达到这个值。

除了设置 socket 外，还需要设置 TCP socket 的读写缓冲区，它们的参数分别是 `net.ipv4.tcp_wmem` 和 `net.ipv4.tcp_rmem`。这些参数的值由 3 个整数组成，它们使用空格分隔，分别表示最小值、默认值和最大值。最大值不能大于 `net.core.wmem_max` 和 `net.core.rmem_max` 指定的大小。例如，“4096 65536 2048000” 表示最小值是 4KB、默认值是 64KB、最大值是 2MB。根据 Kafka 服务器接收流量的实际情况，可能需要设置更高的最大值，为网络连接提供更大的缓冲空间。

还有其他一些有用的网络参数。例如，把 `net.ipv4.tcp_window_scaling` 设为 1，启用 TCP 时间窗扩展，可以提升客户端传输数据的速率，传输的数据可以在服务器端进行缓冲。把 `net.ipv4.tcp_max_syn_backlog` 设为比默认值 1024 更大的值，可以接受更多的并发连接。把 `net.core.netdev_max_backlog` 设为比默认值 1000 更大的值，有助于应对网络流量的爆发，特别是在使用千兆网络的情况下，允许更多的数据包排队等待内核处理。

# 9 生产环境的注意事项

当你准备把 Kafka 从测试环境部署到生产环境时，需要注意一些事项，以便创建更可靠的消息服务。

## 9.1 垃圾回收器选项

为应用程序调整 Java 垃圾回收参数就像是一门艺术，我们需要知道应用程序是如何使用内存的，还需要大量的观察和试错。幸运的是，Java 7 为我们带来了 G1 垃圾回收器，让这种状况有所改观。在应用程序的整个生命周期，G1 会自动根据工作负载情况进行自我调节，而且它的停顿时间是恒定的。它可以轻松地处理大块的堆内存，把堆内存分为若干小块的区域，每次停顿时并不会对整个堆空间进行回收。

正常情况下，G1 只需要很少的配置就能完成这些工作。以下是 G1 的两个调整参数。

`MaxGCPauseMillis`：

该参数指定每次垃圾回收默认的停顿时间。该值不是固定的，G1 可以根据需要使用更长的时间。它的默认值是 200ms。也就是说，G1 会决定垃圾回收的频率以及每一轮需要回收多少个区域，这样算下来，每一轮垃圾回收大概需要 200ms 的时间。

`InitiatingHeapOccupancyPercent`：

该参数指定了在 G1 启动新一轮垃圾回收之前可以使用的堆内存百分比，默认值是 45。也就是说，在堆内存的使用率达到 45% 之前，G1 不会启动垃圾回收。这个百分比包括新生代和老年代的内存。

Kafka 对堆内存的使用率非常高，容易产生垃圾对象，所以可以这些值设得小一些。如果一台服务器有 64GB 内存，并且使用 5GB 堆内存来运行 Kafka，那么可以参考以下的配置：`MaxGCPauseMillis` 可以设为 20ms；`InitiatingHeapOccupancyPercent` 可以设为 35，这样可以让垃圾回收比默认的要早一些启动。

Kafka 的启动脚本并没有启用 G1 回收器，而是使用了 Parallel New 和 CMS（Concurrent Mark-Sweep，并发标记和清除）垃圾回收器。不过它可以通过环境变量来修改。

## 9.2 数据中心布局

在开发阶段，人们并不会太关心 Kafka 服务器在数据中心所处的物理位置，因为即使集群在短时间内出现局部或完全不可用，也不会造成太大影响。但是在生产环境，服务不可用意味着金钱的损失，具体表现为无法为用户提供服务或者不知道用户正在做什么。这个时候，使用 Kafka 集群的复制功能就变得尤为重要，而服务器在数据中心所处的物理位置也变得重要起来。如果在部署 Kafka 之前没有考虑好这个问题，那么在后续的维护过程中，移动服务器需要耗费更高的成本。

在为 broker 增加新的分区时，broker 并无法获知机架的信息。也就是说，两个 broker 有可能是在同一个机架上，或者在同一个可用区域里（如果运行在像 AWS 这样的云服务上），所以，在为分区添加副本的时候，这些副本很可能被分配给同一个机架上的 broker，它们使用相同的电源和网络连接。如果该机架出了问题，这些分区就会离线，客户端就无法访问到它们。更糟糕的是，如果发生不完整的主节点选举，那么在恢复时就有可能丢失数据。

所以，最好把集群的 broker 安装在不同的机架上，至少不要让它们共享可能出现单点故障的基础设施，比如电源和网络。也就是说，部署服务器需要至少两个电源连接（两个不同的回路）和两个网络交换器（保证可以进行无缝的故障切换）。除了这些以外，最好还要把 broker 安放在不同的机架上。因为随着时间的推移，机架也需要进行维护，而这会导致机器离线（比如移动机器或者重新连接电源）。

## 9.3 共享 Zookeeper

Kafka 使用 Zookeeper 来保存 broker，主题和分区的元数据信息。对于一个包含多个节点的 Zookeeper 群组来说，Kafka 集群的这些流量并不算多，那些写操作只是用于构造消费者群组或集群本身。实际上，在很多部署环境里，会让多个 Kafka 集群共享一个 Zookeeper 群组（每个集群使用一个 chroot 路径）。

> **Kafka 消费者和 Zookeeper**
>
> 在 Kafka 0.9.0.0 版本之前，除了 broker 之外，消费者也会使用 Zookeeper 来保存一些信息，比如消费者群组的信息、主题信息、消费分区的偏移量（在消费者群组里发生失效转移时会用到）。
>
> 到了 0.9.0.0 版本，Kafka 引入了一个新的消费者接口，允许 broker 直接维护这些信息。

不过，消费者和 Zookeeper 之间还是有一个值得注意的地方，消费者可以选择将偏移量提交到 Zookeeper 或 Kafka，还可以选择提交偏移量的时间间隔。如果消费者将偏移量提交到 Zookeeper，那么在每个提交时间点上，消费者将会为每一个消费的分区往 Zookeeper 写入一次偏移量。合理的提交间隔是 1 分钟，因为这刚好是消费者群组的某个消费者发生失效时能够读取到重复消息的时间。值得注意的是，这些提交对于 Zookeeper 来说流量不算小，特别是当集群里有多个消费者的时候。如果 Zookeeper 群组无法处理太大的流量，就有必要使用长一点的提交时间间隔。不过不管怎样，还是建议使用最新版本的 Kafka，让消费者把偏移量提交到 Kafka 服务器上，消除对 Zookeeper 的依赖。

虽然多个 Kafka 集群可以共享一个 Zookeeper 群组，但如果有可能的话，不建议把 Zookeeper 共享给其他应用程序。Kafka 对 Zookeeper 的延迟和超时比较敏感，与 Zookeeper 群组之间的一个通信异常就可能导致 Kafka 服务器出现无法预测的行为。这样很容易让多个 broker 同时离线，如果它们与 Zookeeper 之间断开连接，也会导致分区离线。这也会给集群控制器带来压力，在服务器离线一段时间之后，当控制器尝试关闭一个服务器时，会表现出一些细小的错误。其他的应用程序因重度使用或进行不恰当的操作给 Zookeeper 群组带来压力，所以最好让它们使用自己的 Zookeeper 群组。

# 参考文档

- 《Apache Kafka 实战》3.1 集群环境规划
- 《Kafka 权威指南》2.4 硬件的选择、2.6 Kafka 集群、2.7 生产环境的注意事项
- Java NIO 和 NIO2：https://www.jianshu.com/p/1016ebe18ad8